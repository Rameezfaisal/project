AnalysisException                         Traceback (most recent call last)
Cell In[46], line 3
      1 sprs_dmd26wk = (
      2     so2
----> 3     .select(
      4         F.col("part").alias("s_part"),
      5         F.col("openqty").cast("int").alias("openqty"),
      6         F.col("ordergroup").alias("ordergroup"),
      7         F.col("orderstatus").alias("orderstatus"),
      8         F.to_date("deliveryduedate", "yyyyMMdd").alias("deliveryduedate_dt"),
      9         F.col("ordertype").alias("ordertype")
     10     )
     11     .alias("s")
     12     .join(
     13         mknha
     14         .select(
     15             F.col("cmpprtno").alias("m_cmpprtno"),
     16             F.col("nha").alias("m_nha")
     17         )
     18         .alias("m"),
     19         F.col("s.s_part") == F.col("m.m_nha"),
     20         "inner"
     21     )
     22     .where(
     23         (F.col("s.ordergroup") == "SO") &
     24         (F.lower(F.col("s.orderstatus")) != "closed") &
     25         (F.col("s.deliveryduedate_dt") >= dt1wk) &
     26         (F.col("s.deliveryduedate_dt") <= dt26wk) &
     27         F.col("s.ordertype").isin("TA","ZCON","ZO09","ZO04","ZSD","ZSO","ZFO","ZUP")
     28     )
     29     .groupBy(
     30         F.col("m.m_cmpprtno").alias("cmpprtno"),
     31         F.col("s.s_part").alias("nha")
     32     )
     33     .agg(
     34         F.sum("s.openqty").cast("int").alias("sprs_dmd")
     35     )
     36 )
     38 sprs_dmd26wk.cache()

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:3229, in DataFrame.select(self, *cols)
   3184 def select(self, *cols: "ColumnOrName") -> "DataFrame":  # type: ignore[misc]
   3185     """Projects a set of expressions and returns a new :class:`DataFrame`.
   3186 
   3187     .. versionadded:: 1.3.0
   (...)
   3227     +-----+---+
   3228     """
-> 3229     jdf = self._jdf.select(self._jcols(*cols))
   3230     return DataFrame(jdf, self.sparkSession)

File ~/cluster-env/trident_env/lib/python3.11/site-packages/py4j/java_gateway.py:1322, in JavaMember.__call__(self, *args)
   1316 command = proto.CALL_COMMAND_NAME +\
   1317     self.command_header +\
   1318     args_command +\
   1319     proto.END_COMMAND_PART
   1321 answer = self.gateway_client.send_command(command)
-> 1322 return_value = get_return_value(
   1323     answer, self.gateway_client, self.target_id, self.name)
   1325 for temp_arg in temp_args:
   1326     if hasattr(temp_arg, "_detach"):

File /opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:185, in capture_sql_exception.<locals>.deco(*a, **kw)
    181 converted = convert_exception(e.java_exception)
    182 if not isinstance(converted, UnknownException):
    183     # Hide where the exception came from that shows a non-Pythonic
    184     # JVM exception message.
--> 185     raise converted from None
    186 else:
    187     raise

AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `part` cannot be resolved. Did you mean one of the following? [`posnr`, `etenr`, `pgiqty`, `carrier`, `pgidate`].;
'Project ['part AS s_part#6833, cast('openqty as int) AS openqty#6834, 'ordergroup AS ordergroup#6835, 'orderstatus AS orderstatus#6836, to_date('deliveryduedate, Some(yyyyMMdd), Some(UTC), false) AS deliveryduedate_dt#6837, 'ordertype AS ordertype#6838]
