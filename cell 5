from pyspark.sql import functions as F

new_make_nha = (
    nha.alias("a")
    .join(
        make_nha
            .select(
                F.col("cmpprtno").alias("b_cmpprtno"),
                F.col("nha").alias("b_nha")
            )
            .alias("b"),
        (F.col("a.cmpprtno") == F.col("b.b_cmpprtno")) &
        (F.col("a.nha") == F.col("b.b_nha")),
        "left"
    )
    .where(
        (F.col("a.cmpprtno") != F.col("a.nha")) &
        F.col("b.b_cmpprtno").isNull() &
        (~F.col("a.nha").like("%DELTA%")) &
        (F.col("a.nha_status_inactive") != "X") &
        (F.col("a.matkl").isin("M","MN","X")) &
        (~F.col("a.mstae").isin("OB","OS","OP"))
    )
    .groupBy(
        F.col("a.cmpprtno").alias("cmpprtno"),
        F.col("a.nha").alias("nha"),
        F.col("a.level").alias("level"),
        F.col("a.matkl").alias("matkl"),
        F.col("a.mstae").alias("mstae")
    )
    .agg(
        # ðŸš¨ Delta INT target â†’ force INT
        F.sum("a.cmpqpa").cast("int").alias("cmpqpa")
    )
    .withColumn("last_modified_on", F.current_date())
    .withColumn("isprocessed", F.lit("N"))
    .select(
        "cmpprtno",
        "cmpqpa",
        "isprocessed",
        "last_modified_on",
        "level",
        "matkl",
        "mstae",
        "nha"
    )
)

new_make_nha.write.mode("append").saveAsTable(make_nha_target_path)