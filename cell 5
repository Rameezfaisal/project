# #### Step-3 -- Reading Source tables (Optimized Reading Strategy)

# 1. Calculate the "Partition Pruning" Year
# If we need 5 years of data, we strictly ignore any fiscal year older than that.
current_year = int(today.format("yyyy")) if hasattr(today, 'format') else 2026 # Adjust safety default
start_year = current_year - 6 # Safety buffer

print(f"Pruning MSEG partitions older than year: {start_year}")

# 2. Optimized Read Function with "Push-Down Filters"
def read_filtered_union(table_key, year_col, min_year, date_col=None, min_date=None):
    ecc_path = paths["ecc"].get(table_key)
    s4h_path = paths["s4h"].get(table_key)
    
    dfs = []
    for path in [ecc_path, s4h_path]:
        try:
            df = spark.read.table(path)
            
            # CRITICAL: Apply Partition Filter IMMEDIATELY upon read
            if year_col and min_year:
                df = df.filter(F.col(year_col) >= min_year)
            
            # Apply Date Filter if applicable (for MKPF)
            if date_col and min_date:
                df = df.filter(F.col(date_col) >= min_date)
                
            dfs.append(df)
        except Exception:
            continue
            
    if not dfs:
        raise ValueError(f"No data found for {table_key}")
        
    # Align schemas and union
    all_cols = sorted(set(dfs[0].columns) | set(dfs[1].columns)) if len(dfs) > 1 else dfs[0].columns
    
    aligned_dfs = [
        df.select([F.col(c) if c in df.columns else F.lit(None).alias(c) for c in all_cols])
        for df in dfs
    ]
    
    return aligned_dfs[0].unionByName(aligned_dfs[1]) if len(aligned_dfs) > 1 else aligned_dfs[0]

# 3. Read Tables with Optimized Strategy
# Only read MKPF where Date > 5 Years ago
mkpf = read_filtered_union("mkpf", "mjahr", start_year, "bldat", F.date_sub(today, 365*6))

# Only read MSEG where Fiscal Year (MJAHR) > 5 Years ago
# We also SELECT specific columns to reduce I/O overhead
mseg_full = read_filtered_union("mseg", "mjahr", start_year)
mseg = mseg_full.select("mblnr", "mjahr", "zeile", "matnr", "menge", "shkzg", "bwart")

# Read other tables normally
makt      = read_union_fast("makt")
forecast  = read_union_fast("zmmforecast")
mard      = read_union_fast("mard")
po        = read_union_fast("zpo_hstry")
ekpo      = read_union_fast("ekpo")

spares = spark.table("wsf_silk_glb_dt_qa.lhg_glb.eng.rpt_csbg_spares_deliveries")
suppliers_by_plant = spark.table("lhs_glb.omat_test.rpt_omat_buynha_suppliers_plants")

# Re-establish Scope
nha = spark.table("lhs_glb.omat_test.rpt_omat_obpn_buy_nha_dtls") \
           .select("cmpprtno", "nha", "isprocessed") \
           .filter(F.col("isprocessed") == "N") \
           .distinct()








# #### Step-5 (Consolidated) -- Manufacturing Consumption
# OPTIMIZATION: Uses the Partition-Pruned MSEG dataframe from Step 3.

mfg_all = (
    mseg.join(mkpf, ["mblnr", "mjahr"], "inner") # Join on both keys is faster
        # 1. Broadcast the small nhalist
        .join(F.broadcast(nhalist), mseg.matnr == nhalist.nha) 
        .filter(
            (mseg.bwart.isin("261","262")) 
            # Note: The heavy date filtering was already done in Step 3!
            # We just apply the exact logic here for the columns.
        )
        .groupBy(nhalist.cmpprtno.alias("cmpprtno_cd"), mseg.matnr.alias("nha_cd"))
        .agg(
            # 12 Month Logic
            F.sum(
                F.when((mkpf.bldat > F.date_sub(today, 365)) & (mseg.shkzg=="S"), -mseg.menge)
                 .when((mkpf.bldat > F.date_sub(today, 365)), mseg.menge)
                 .otherwise(0)
            ).alias("mfg_12mnths_consumption"),
            
            # 3 Year Logic
            F.sum(
                F.when((mkpf.bldat > F.date_sub(today, 365*3)) & (mseg.shkzg=="S"), -mseg.menge)
                 .when((mkpf.bldat > F.date_sub(today, 365*3)), mseg.menge)
                 .otherwise(0)
            ).alias("mfg_3yrs_consumption"),
            
            # 5 Year Logic (Base)
            F.sum(
                F.when(mseg.shkzg=="S", -mseg.menge).otherwise(mseg.menge)
            ).alias("mfg_5yrs_consumption")
        )
)





