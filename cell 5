# FIX: Add .dropDuplicates(["nha"]) to handle pre-existing duplicates in the table

df_choice = (
    df_sel
    .withColumn(
        "omat_selected_plant",
        F.when(F.length("suppcd_2000")>0,"2000")
         # ... (rest of your logic) ...
         .when(F.length("suppcd_pr")>0,"2000")
    )
    .withColumn(
        "omat_selected_suppliercd",
         # ... (rest of your logic) ...
    )
    .withColumn(
        "omat_selected_supplier",
         # ... (rest of your logic) ...
    )
    .dropDuplicates(["nha"])  # <--- ADD THIS LINE HERE
)

delta_tbl = DeltaTable.forName(spark, tgt_suppliers)

(
    delta_tbl.alias("t")
    .merge(df_choice.alias("s"), "t.nha = s.nha")
    .whenMatchedUpdate(set={
        "omat_selected_plant":"s.omat_selected_plant",
        "omat_selected_suppliercd":"s.omat_selected_suppliercd",
        "omat_selected_supplier":"s.omat_selected_supplier"
    })
    .execute()
)









# In Step 6
df_sup = (
    df_nha.alias("a")
    .join(...) 
    .select(...)
    .distinct()  # <--- Add this to match SAP's "SELECT DISTINCT"
)


