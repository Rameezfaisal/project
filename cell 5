# ============================
# Cell 8 â€“ Back-fill missing suppliers from EORD
# ============================

from delta.tables import DeltaTable

# Load target table
df_tgt = spark.read.table(tgt_suppliers)

# Only rows that SAP wants to update (all plant suppliers missing)
df_missing = (
    df_tgt
    .filter(
        (F.coalesce(F.length("suppcd_1900"),F.lit(0)) == 0) &
        (F.coalesce(F.length("suppcd_2000"),F.lit(0)) == 0) &
        (F.coalesce(F.length("suppcd_3120"),F.lit(0)) == 0) &
        (F.coalesce(F.length("suppcd_1050"),F.lit(0)) == 0) &
        (F.coalesce(F.length("suppcd_1060"),F.lit(0)) == 0) &
        (F.coalesce(F.length("suppcd_1090"),F.lit(0)) == 0)
    )
)

# Build EORD dimension (only preferred suppliers)
df_eord_pref = (
    df_eord
    .filter((F.col("autet")=="1") & (F.col("flifn")=="X"))
    .select(
        F.trim("matnr").alias("nha_cd"),
        F.col("werks").alias("plant_cd"),
        F.col("lifnr").alias("suppcd")
    )
)

df_eord_pref = (
    df_eord_pref
    .join(df_lfa1.select("lifnr","name1"), "lifnr", "left")
    .select(
        "nha_cd","plant_cd",
        F.col("lifnr").alias("suppcd"),
        F.col("name1").alias("suppname")
    )
)

# Pivot plants to columns
df_eord_pivot = (
    df_eord_pref
    .groupBy("nha_cd")
    .pivot("plant_cd", ["1900","2000","3120","1050","1060","1090","1000","1010","1020"])
    .agg(F.first(F.struct("suppcd","suppname")))
)

# Flatten pivot
df_eord_flat = (
    df_eord_pivot
    .select(
        "nha_cd",

        F.col("1900.suppcd").alias("e_suppcd_1900"),
        F.col("1900.suppname").alias("e_suppname_1900"),

        F.col("2000.suppcd").alias("e_suppcd_2000"),
        F.col("2000.suppname").alias("e_suppname_2000"),

        F.col("3120.suppcd").alias("e_suppcd_3120"),
        F.col("3120.suppname").alias("e_suppname_3120"),

        F.col("1050.suppcd").alias("e_suppcd_1050"),
        F.col("1050.suppname").alias("e_suppname_1050"),

        F.col("1060.suppcd").alias("e_suppcd_1060"),
        F.col("1060.suppname").alias("e_suppname_1060"),

        F.col("1090.suppcd").alias("e_suppcd_1090"),
        F.col("1090.suppname").alias("e_suppname_1090"),

        F.col("1000.suppcd").alias("e_suppcd_1000"),
        F.col("1000.suppname").alias("e_suppname_1000"),

        F.col("1010.suppcd").alias("e_suppcd_1010"),
        F.col("1010.suppname").alias("e_suppname_1010"),

        F.col("1020.suppcd").alias("e_suppcd_1020"),
        F.col("1020.suppname").alias("e_suppname_1020"),
    )
)

# Build final update rows (with SAP fallback logic)
df_update = (
    df_missing.alias("t")
    .join(df_eord_flat.alias("e"), F.col("t.nha")==F.col("e.nha_cd"))
    .select(
        F.col("t.nha"),

        F.coalesce("e.e_suppcd_1900","e.e_suppcd_1020").alias("suppcd_1900"),
        F.coalesce("e.e_suppname_1900","e.e_suppname_1020").alias("suppname_1900"),

        F.coalesce("e.e_suppcd_2000","e.e_suppcd_1000").alias("suppcd_2000"),
        F.coalesce("e.e_suppname_2000","e.e_suppname_1000").alias("suppname_2000"),

        F.coalesce("e.e_suppcd_3120","e.e_suppcd_1010").alias("suppcd_3120"),
        F.coalesce("e.e_suppname_3120","e.e_suppname_1010").alias("suppname_3120"),

        "e.e_suppcd_1050","e.e_suppname_1050",
        "e.e_suppcd_1060","e.e_suppname_1060",
        "e.e_suppcd_1090","e.e_suppname_1090"
    )
)

# Delta MERGE (SAP UPDATE equivalent)
delta_tbl = DeltaTable.forName(spark, tgt_suppliers)

(
    delta_tbl.alias("t")
    .merge(df_update.alias("s"), "t.nha = s.nha")
    .whenMatchedUpdate(set={
        "suppcd_1900":"s.suppcd_1900",
        "suppname_1900":"s.suppname_1900",
        "suppcd_2000":"s.suppcd_2000",
        "suppname_2000":"s.suppname_2000",
        "suppcd_3120":"s.suppcd_3120",
        "suppname_3120":"s.suppname_3120",
        "suppcd_1050":"s.e_suppcd_1050",
        "suppname_1050":"s.e_suppname_1050",
        "suppcd_1060":"s.e_suppcd_1060",
        "suppname_1060":"s.e_suppname_1060",
        "suppcd_1090":"s.e_suppcd_1090",
        "suppname_1090":"s.e_suppname_1090"
    })
    .execute()
)