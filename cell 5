from pyspark.sql import functions as F

mfg_dmd26wk = (
    mdkp
    .select(
        F.col("dtnum").alias("d_dtnum"),
        F.col("matnr").alias("d_matnr"),
        F.col("plwrk").cast("int").alias("plwrk")
    )
    .alias("d")
    .join(
        mknha
        .select(
            F.col("cmpprtno").alias("m_cmpprtno"),
            F.col("nha").alias("m_nha")
        )
        .alias("m"),
        F.col("d.d_matnr") == F.col("m.m_nha"),
        "inner"
    )
    .join(
        mdtb
        .select(
            F.col("dtnum").alias("f_dtnum"),
            F.to_date("dat00", "yyyyMMdd").alias("dat00_dt"),
            F.col("plumi").alias("plumi"),
            F.col("mng01").cast("int").alias("mng01"),
            F.col("delkz").alias("delkz")
        )
        .alias("f"),
        F.col("d.d_dtnum") == F.col("f.f_dtnum"),
        "inner"
    )
    .where(
        F.col("f.plumi").isin("+", "-") &
        ((F.col("d.plwrk") < 2001) | (F.col("d.plwrk") == 3120)) &
        F.col("f.delkz").isin("AR", "SB") &
        (F.col("f.dat00_dt") >= dt1wk) &
        (F.col("f.dat00_dt") <= dt26wk)
    )
    .groupBy(
        F.col("m.m_cmpprtno").alias("cmpprtno"),
        F.col("d.d_matnr").alias("nha")
    )
    .agg(
        F.sum(
            F.when(F.col("f.plumi") == "-", F.col("f.mng01"))
             .otherwise(-F.col("f.mng01"))
        ).cast("int").alias("mfg_dmd")
    )
)

mfg_dmd26wk.cache()