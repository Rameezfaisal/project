üü¶ Cell 7 ‚Äì Build NEWLIST (Order BOM ‚Üî NHA Mapping)


This step establishes the core relationship between Order BOMs and NHAs that:
Drives consumption calculations
Drives QOH and PO quantity rollups
Acts as the bridge dataset for all downstream joins
In business terms:
‚ÄúFor every NHA in scope, identify all contributing Order BOM materials.‚Äù




newlist_df = (
    spark.read.table("eng_test.rpt_omat_odrbom_dmd_dtls")
    .select(
        F.col("odrbom").alias("odrbom"),
        F.col("nha").alias("nha")
    )
    .distinct()
)

# Register as temp view to mirror SAP temp table
newlist_df.createOrReplaceTempView("newlist")









üü¶ Cell 8 ‚Äì Build & Insert Order-BOM Consumption Details (261 / 262)


This step calculates actual material consumption for Order BOMs:
Uses goods issue / reversal movements (261 / 262)
Applies sign correction based on debit/credit (SHKZG)
Restricts data to last 5 years
Ties consumption back to NHA via Order BOM
In business terms:
‚ÄúHow much material was actually consumed for manufacturing over the last 5 years?‚Äù







odrbom_cons_df = (
    newlist_df.alias("a")
    .join(
        mseg_df.alias("b"),
        F.col("b.matnr") == F.col("a.odrbom"),
        "inner"
    )
    .join(
        makt_df.alias("c"),
        F.col("c.matnr") == F.col("b.matnr"),
        "inner"
    )
    .join(
        mkpf_df.alias("d"),
        F.col("b.mblnr") == F.col("d.mblnr"),
        "inner"
    )
    .filter(
        F.col("b.bwart").isin("261", "262")
        & (F.col("d.bldat") > F.date_add(F.current_date(), -five_year_days))
        & (F.col("d.bldat") < F.current_date())
        & (F.col("b.cpudt_mkpf") > F.date_add(F.current_date(), -five_year_days))
    )
    .select(
        F.col("d.bldat").alias("cons_date"),
        F.when(F.col("b.shkzg") == "S", -1 * F.col("b.menge"))
         .otherwise(F.col("b.menge"))
         .cast("decimal(13,3)")
         .alias("menge"),
        F.col("a.nha").alias("nha"),
        F.col("a.odrbom").alias("odrbom")
    )
    .filter(F.col("menge").isNotNull())   # Delta NOT NULL safety
    .distinct()
)





(
    odrbom_cons_df
    .select("cons_date", "menge", "nha", "odrbom")
    .write
    .mode("append")
    .saveAsTable("eng_test.rpt_omat_odrbom_cons_dtls")
)






üü¶ Cell 9 ‚Äì Build NEW_DMD (Aggregate Demand per ODRBOM & NHA)


Business purpose
This step consolidates period-wise demand into a single demand number (DMD) for each:
NHA
Order BOM
Demand type (ROWTYPE)
In business terms:
‚ÄúWhat is the total manufacturing demand for each Order BOM across all forecast periods?‚Äù
This dataset is later used to:
Compute manufacturing demand rollups
Compare demand vs consumption







new_dmd_df = (
    spark.read.table("eng_test.rpt_omat_odrbom_dmd_dtls")
    .select(
        F.col("nha").alias("nha"),
        F.col("odrbom").alias("odrbom"),
        F.col("rowtype").alias("rowtype"),
        (
            F.col("dmdpd")
            + F.col("dmd1")  + F.col("dmd2")  + F.col("dmd3")  + F.col("dmd4")
            + F.col("dmd5")  + F.col("dmd6")  + F.col("dmd7")  + F.col("dmd8")
            + F.col("dmd9")  + F.col("dmd10") + F.col("dmd11") + F.col("dmd12")
            + F.col("dmd13") + F.col("dmd14") + F.col("dmd15") + F.col("dmd16")
            + F.col("dmd17") + F.col("dmd18") + F.col("dmd19") + F.col("dmd20")
            + F.col("dmd21") + F.col("dmd22") + F.col("dmd23") + F.col("dmd24")
            + F.col("dmd25") + F.col("dmd26")
        ).alias("dmd")
    )
    .distinct()
)

# Register as SAP-like temp table
new_dmd_df.createOrReplaceTempView("new_dmd")



