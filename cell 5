# #### Step-5 (Consolidated) -- Manufacturing Consumption (12mo, 3yr, 5yr)
# OPTIMIZATION: Reads MSEG only once instead of 3 times.

mfg_all = (
    mseg.join(mkpf, "mblnr")
        # 1. Broadcast the small nhalist
        .join(F.broadcast(nhalist), mseg.matnr == nhalist.nha) 
        .filter(
            (mseg.bwart.isin("261","262")) &
            # 2. Filter for the WIDEST date range (5 years)
            (mkpf.bldat > F.date_sub(today, 365*5))
        )
        .groupBy(nhalist.cmpprtno.alias("cmpprtno_cd"), mseg.matnr.alias("nha_cd"))
        .agg(
            # 3. Use Conditional Sums for narrower ranges
            F.sum(
                F.when((mkpf.bldat > F.date_sub(today, 365)) & (mseg.shkzg=="S"), -mseg.menge)
                 .when((mkpf.bldat > F.date_sub(today, 365)), mseg.menge)
                 .otherwise(0)
            ).alias("mfg_12mnths_consumption"),
            
            F.sum(
                F.when((mkpf.bldat > F.date_sub(today, 365*3)) & (mseg.shkzg=="S"), -mseg.menge)
                 .when((mkpf.bldat > F.date_sub(today, 365*3)), mseg.menge)
                 .otherwise(0)
            ).alias("mfg_3yrs_consumption"),
            
            F.sum(
                F.when(mseg.shkzg=="S", -mseg.menge).otherwise(mseg.menge)
            ).alias("mfg_5yrs_consumption")
        )
)








# #### Step-6 (Consolidated) -- Mfg & Spares Demand
# OPTIMIZATION: Reads Forecast table only once.

dmd_cols = ["dmdpd"] + [f"dmd{i}" for i in range(1,27)]
# Create a single expression to sum all dmd columns
total_dmd_expr = sum(F.col(c) for c in dmd_cols)

demand_all = (
    forecast
    .join(F.broadcast(nhalist), forecast.matnr == nhalist.nha, "inner")
    .filter(
        (forecast.werks == "COMB") &
        (forecast.rowtype.isin("06", "07")) # Filter for both types
    )
    .groupBy(
        nhalist.cmpprtno.alias("cmpprtno_cd"),
        forecast.matnr.alias("nha_cd")
    )
    .agg(
        # Conditional Sum based on Row Type
        F.sum(F.when(forecast.rowtype == "06", total_dmd_expr).otherwise(0)).alias("mfg_dmd"),
        F.sum(F.when(forecast.rowtype == "07", total_dmd_expr).otherwise(0)).alias("sprs_dmd")
    )
)









# #### Step-8 (Consolidated) -- Spares Consumption (3yr, 5yr)
# OPTIMIZATION: Reads Spares table only once.

sprs_all = (
    spares
    .join(F.broadcast(nhalist), spares.material == nhalist.nha, "inner")
    .filter(
        (spares.source_doc != "STO") &
        (spares.order_type.isin("TA","ZCON","ZO09","ZO04","ZSD","ZSO","ZFO","ZUP")) &
        # Filter for widest range (5 years)
        (spares.actual_gi > F.date_sub(F.current_date(), 365*5))
    )
    .groupBy(
        nhalist.cmpprtno.alias("cmpprtno_cd"),
        spares.material.alias("nha_cd")
    )
    .agg(
        F.sum(
            F.when(spares.actual_gi > F.date_sub(F.current_date(), 365*3), spares.qty_shipped)
             .otherwise(0)
        ).alias("sprs_3yrs_consumption"),
        
        F.sum(spares.qty_shipped).alias("sprs_5yrs_consumption")
    )
)









# #### Step-11 -- Final Consolidated Insert

base = (
    nhalist.alias("a")
    .join(mfg_all.alias("b"), nhalist.nha == mfg_all.nha_cd, "left")
    .join(demand_all.alias("c"), nhalist.nha == demand_all.nha_cd, "left")
    .join(sprs_all.alias("d"), nhalist.nha == sprs_all.nha_cd, "left")
    .join(lamqoh.alias("g"), nhalist.nha == lamqoh.nha_cd, "left")
    .join(openpo.alias("h"), nhalist.nha == openpo.nha_cd, "left")
    .select(
        nhalist.cmpprtno.alias("cmpprtno"),
        nhalist.nha.alias("nha"),
        # MFG Metrics (From mfg_all)
        F.col("b.mfg_3yrs_consumption").cast("int"),
        F.col("b.mfg_12mnths_consumption").cast("int"),
        F.col("b.mfg_5yrs_consumption").cast("int"),
        # Demand Metrics (From demand_all)
        F.col("c.mfg_dmd").cast("int"),
        F.col("c.sprs_dmd").cast("int"),
        # Spares Metrics (From sprs_all)
        F.col("d.sprs_3yrs_consumption").cast("int"),
        F.col("d.sprs_5yrs_consumption").cast("int"),
        # QOH & PO (Unchanged)
        F.col("g.lamqoh").cast("int"),
        F.col("g.restricted_all_stock").cast("int"),
        F.col("h.open_po_qty").cast("int")
    )
)

final = base.filter(
    (F.col("cmpprtno") == F.col("nha")) |
    (
        (F.coalesce(F.col("mfg_3yrs_consumption"), F.lit(0)) > 0) |
        (F.coalesce(F.col("mfg_dmd"), F.lit(0)) > 0) |
        (F.coalesce(F.col("sprs_dmd"), F.lit(0)) > 0) |
        (F.coalesce(F.col("sprs_3yrs_consumption"), F.lit(0)) > 0) |
        (F.coalesce(F.col("mfg_12mnths_consumption"), F.lit(0)) > 0) |
        (F.coalesce(F.col("open_po_qty"), F.lit(0)) > 0) |
        (F.coalesce(F.col("mfg_5yrs_consumption"), F.lit(0)) > 0) |
        (F.coalesce(F.col("sprs_5yrs_consumption"), F.lit(0)) > 0)
    )
).withColumn("last_modified_on", F.current_date())

final.createOrReplaceTempView("final_dmd")

# (Keep your existing INSERT SQL statement here)
spark.sql(f"""
INSERT INTO {tgt_dmd} ...
""")
