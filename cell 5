Cell 12 — Mark MAKE-NHAs as Processed
Business purpose
Once demand and consumption have been calculated and written, all new MAKE-NHAs used in this run must be marked as processed so that:
They are not reprocessed in the next run, and
The next execution only picks up truly new NHAs.





spark.sql(f"""
UPDATE {make_nha_target_path}
SET isprocessed = 'Y'
WHERE isprocessed = 'N'
""")






Cell 13 — Logging / Audit INSERT (OMAT_LOG_DTLS)
Business purpose
Create a single audit record for this execution capturing:
When the job ran
How many OB parent parts were processed
How many NHAs were processed
A run indicator (always 1 for a successful execution)
The program/notebook name





# Compute counts (same as SAP variables)
obprtno_cnt = mknha.select("cmpprtno").distinct().count()
obprtno_nha_cnt = mknha.select("nha").distinct().count()

# Insert audit record with explicit column list (Delta-safe)
spark.sql(f"""
INSERT INTO {log_table_path} (
    executed_on,
    obprtno_cnt,
    obprtno_nha_cnt,
    obpr_cnt,
    program_name
)
VALUES (
    current_timestamp(),
    {obprtno_cnt},
    {obprtno_nha_cnt},
    1,
    'SP_OMAT_INSERT_MAKENHA_DMD_CONS'
)
""")