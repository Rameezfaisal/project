# ---- Calculate counts (SAP OBPRTCnt / NHACnt equivalents) ----
obprtno_cnt = df_nhamainlist.select("cmpprtno_cd").distinct().count()
obpr_cnt = df_nhamainlist.select("nha_cd").distinct().count()
obprtno_nha_cnt = df_nhamainlist.count()   # total CMPPRTNOâ€“NHA pairs

# ---- Create start log row ----
df_log_start = spark.createDataFrame(
    [(
        F.current_timestamp(),
        obprtno_cnt,
        obprtno_nha_cnt,
        obpr_cnt,
        "SP_OMAT_UPDATEDMD_CONS_MKNHA_WklyRefresh - Started"
    )],
    ["executed_on", "obprtno_cnt", "obprtno_nha_cnt", "obpr_cnt", "program_name"]
)

# ---- Create end log row ----
df_log_end = spark.createDataFrame(
    [(
        F.current_timestamp(),
        obprtno_cnt,
        obprtno_nha_cnt,
        obpr_cnt,
        "SP_OMAT_UPDATEDMD_CONS_MKNHA_WklyRefresh - End"
    )],
    ["executed_on", "obprtno_cnt", "obprtno_nha_cnt", "obpr_cnt", "program_name"]
)

# ---- Append both records to Delta log table ----
df_log_start.write.format("delta").mode("append").saveAsTable("eng_test.rpt_omat_log_dtls")
df_log_end.write.format("delta").mode("append").saveAsTable("eng_test.rpt_omat_log_dtls")








SELECT *
FROM eng_test.rpt_omat_log_dtls
ORDER BY executed_on DESC
LIMIT 2;
