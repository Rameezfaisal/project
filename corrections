PySparkTypeError                          Traceback (most recent call last)
Cell In[178], line 26
      1 # ============================
      2 # Cell 9 â€“ Build POSUPP (Open PO suppliers)
      3 # ============================
      5 df_posupp = (
      6     df_nha.alias("a")
      7 
      8     .join(df_dmd.alias("d"), F.col("a.nha_cd") == F.col("d.nha"))
      9 
     10     .join(df_po_hist.alias("p"), F.col("p.matnr") == F.col("a.nha_cd"))
     11 
     12     .join(
     13         df_ekpo.alias("e"),
     14         (F.col("p.ebeln") == F.col("e.ebeln")) &
     15         (F.col("p.ebelp") == F.col("e.ebelp"))
     16     )
     17 
     18     .join(
     19         df_lfa1.alias("l"),
     20         F.lpad(F.col("p.lifnr"),10,"0") == F.lpad(F.col("l.lifnr"),10,"0"),
     21         "left"
     22     )
     23 
     24     .filter(
     25         (F.col("d.open_po_qty") > 0) &
---> 26         (~F.right("p.due_dt",5).isin("04-01","12-31")) &
     27         (F.col("p.status") != "INACT") &
     28         (F.trim("p.matnr") != "") &
     29         (F.trim("p.loekz") == "") &
     30         (F.col("p.discrd") != "X") &
     31         (F.col("p.aussl") != "U3") &
     32         (F.col("p.bsart") != "UB") &
     33         (F.col("p.elikz") != "X") &
     34         (~F.col("e.pstyp").isin([7, 9]))    # ðŸ”¥ FIX
     35     )
     36 
     37     .select(
     38         F.col("a.nha_cd").alias("nha"),
     39         F.lpad(F.col("p.lifnr"),10,"0").alias("suppcd"),
     40         F.col("l.name1").alias("suppname")
     41     )
     42     .distinct()
     43     .groupBy("nha")
     44     .agg(
     45         F.concat_ws(",", F.collect_list("suppcd")).alias("posupp_cd"),
     46         F.concat_ws(",", F.collect_list("suppname")).alias("posupp_name")
     47     )
     48 )
     50 df_posupp.createOrReplaceTempView("posupp")

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py:174, in try_remote_functions.<locals>.wrapped(*args, **kwargs)
    172     return getattr(functions, f.__name__)(*args, **kwargs)
    173 else:
--> 174     return f(*args, **kwargs)

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/functions.py:10938, in right(str, len)
  10917 @try_remote_functions
  10918 def right(str: "ColumnOrName", len: "ColumnOrName") -> Column:
  10919     """
  10920     Returns the rightmost `len`(`len` can be string type) characters from the string `str`,
  10921     if `len` is less or equal than 0 the result is an empty string.
   (...)
  10936     [Row(r='SQL')]
  10937     """
> 10938     return _invoke_function_over_columns("right", str, len)

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/functions.py:105, in _invoke_function_over_columns(name, *cols)
    100 def _invoke_function_over_columns(name: str, *cols: "ColumnOrName") -> Column:
    101     """
    102     Invokes n-ary JVM function identified by name
    103     and wraps the result with :class:`~pyspark.sql.Column`.
    104     """
--> 105     return _invoke_function(name, *(_to_java_column(col) for col in cols))

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/functions.py:105, in <genexpr>(.0)
    100 def _invoke_function_over_columns(name: str, *cols: "ColumnOrName") -> Column:
    101     """
    102     Invokes n-ary JVM function identified by name
    103     and wraps the result with :class:`~pyspark.sql.Column`.
    104     """
--> 105     return _invoke_function(name, *(_to_java_column(col) for col in cols))

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/column.py:65, in _to_java_column(col)
     63     jcol = _create_column_from_name(col)
     64 else:
---> 65     raise PySparkTypeError(
     66         error_class="NOT_COLUMN_OR_STR",
     67         message_parameters={"arg_name": "col", "arg_type": type(col).__name__},
     68     )
     69 return jcol

PySparkTypeError: [NOT_COLUMN_OR_STR] Argument `col` should be a Column or str, got int.
