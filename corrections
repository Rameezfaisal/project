spark.sql(f"""
INSERT INTO {tbl_omat_obprt_tgt}
SELECT
    d.ob_prno                AS obprno,
    d.ob_prtno               AS obprtno,
    d.part_status_cd         AS part_status,
    d.obpr_state_cd          AS obpr_state,
    d.is_ltb_avail_cd        AS is_ltb_avail,
    d.ltb_date_cd            AS ltb_date,
    d.ltb_qty                AS ltb_qty,
    r.reltd_ob_prs           AS reltd_ob_pr,
    CASE
        WHEN r.reltd_ob_prs IS NOT NULL THEN 'Yes'
        ELSE 'No'
    END                      AS duplicate_pr_flag,
    ''                       AS business_unit,
    ''                       AS pg_pm,
    ''                       AS enditem,
    d.is_obprt_processed     AS is_obprt_processed,
    current_timestamp()      AS created_on,
    current_timestamp()      AS last_modified_on,
    d.supplier_date_to_zero_cd  AS supplier_date_to_zero,
    'A'                      AS is_weekly_processed
FROM (
    SELECT
        ob_prno,
        ob_prtno,
        part_status_cd,
        obpr_state_cd,
        is_ltb_avail_cd,
        ltb_date_cd,
        ltb_qty,
        is_obprt_processed,
        supplier_date_to_zero_cd
    FROM obprdtls
) d
LEFT JOIN related_prs r
  ON d.ob_prno  = r.ob_prno
 AND d.ob_prtno = r.ob_prtno
""")







NumberFormatException: [CAST_INVALID_INPUT] The value '' of the type "STRING" cannot be cast to "INT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 2, position 1) ==
INSERT INTO eng_test.rpt_omat_obprtno_dtls
