obpr_info_df = spark.table(tbl_obpr_info).select(
    F.col("obprno").alias("obprno_info"),
    F.col("obprtno").alias("obprtno_info")
).distinct()

# Enforce SAP join condition
ob_base_df = ob_base_df.alias("o") \
    .join(
        obpr_info_df.alias("i"),
        (F.col("o.obprno") == F.col("i.obprno_info")) &
        (F.col("o.obprtno") == F.col("i.obprtno_info")),
        "inner"
    ) \
    .select("o.*") \
    .distinct()

ob_base_df.cache()
ob_base_df.count()
