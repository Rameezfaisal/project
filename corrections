Cell 12 â€” Write to OMAT Tables + Log Execution
What this step does in business terms
This is the commit step.
Everything we calculated in memory is now:
Written into the OMAT reporting table
Audited in the OMAT log table








# ===============================
# 1. Final dataset
# ===============================
df_final = spark.table("stage7_final_suppliers")

# ===============================
# 2. Replace target table (full refresh)
# ===============================
(
    df_final
    .select(
        "nha",
        "omat_selected_plant",
        "omat_selected_supplier",
        "omat_selected_suppliercd",
        "suppcd_1050",
        "suppcd_1060",
        "suppcd_1090",
        "suppcd_1900",
        "suppcd_2000",
        "suppcd_3120",
        "suppcd_po1",
        "suppcd_po2",
        "suppcd_pr",
        "suppname_1050",
        "suppname_1060",
        "suppname_1090",
        "suppname_1900",
        "suppname_2000",
        "suppname_3120",
        "suppname_po1",
        "suppname_po2",
        "suppname_pr"
    )
    .write
    .mode("overwrite")
    .format("delta")
    .option("overwriteSchema", "true")
    .saveAsTable(tgt_suppliers_tbl)
)

# ===============================
# 3. Insert execution log
# ===============================
log_df = spark.createDataFrame(
    [(None, None, None, None, program_name)],
    ["executed_on", "obprtno_cnt", "obprtno_nha_cnt", "obpr_cnt", "program_name"]
).withColumn("executed_on", F.current_timestamp())

(
    log_df
    .write
    .mode("append")
    .format("delta")
    .saveAsTable(tgt_log_tbl)
)
