from pyspark.sql import functions as F

# Step 1: Join and PROJECT clean columns (no aggregation yet)
joined_df = (
    obprdtls_df.alias("d")
    .join(
        df_omat_src.alias("o"),
        (F.col("d.ob_prtno") == F.col("o.obprtno")) &
        (~F.upper(F.col("o.obpr_state")).isin("CLOSED", "CANCELLED")),
        "left"
    )
    .join(
        df_iplm.alias("p"),
        (F.col("p.part_name") == F.col("d.ob_prtno")) &
        (F.col("p.name") != F.col("d.ob_prno")) &
        (F.upper(F.col("p.state")) != "CLOSED") &
        (
            (F.upper(F.col("p.state")).isin("CONFIRMED","IN REVIEW","IN WORK")) |
            (F.upper(F.col("p.disposition")).isin("CONFIRMED","DEFER"))
        ) &
        (F.upper(F.col("p.reason")) == "OBSOLETE COMPONENT"),
        "left"
    )
    .select(
        F.col("d.ob_prno").alias("ob_prno"),
        F.col("d.ob_prtno").alias("ob_prtno"),
        F.col("o.obprtno").alias("omat_obprtno"),
        F.col("o.reltd_ob_pr").alias("omat_reltd_ob_pr"),
        F.col("p.name").alias("iplm_prno")
    )
)

# Step 2: Aggregate (now columns are unambiguous)
related_prs_df = (
    joined_df
    .groupBy("ob_prno", "ob_prtno")
    .agg(
        F.when(
            F.count("omat_obprtno") == 0,
            F.concat_ws(",", F.collect_set("iplm_prno"))
        )
        .otherwise(F.max("omat_reltd_ob_pr"))
        .alias("reltd_ob_prs")
    )
)

related_prs_df.createOrReplaceTempView("related_prs")