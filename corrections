from pyspark.sql import functions as F

# Check for duplicates in any level that would affect the join
# SAP groups by NHA, so we check if NHA is unique per level
duplicate_check = (
    df_nhalist
    .groupBy("level", "nha")
    .agg(F.count("*").alias("cnt"))
    .filter(F.col("cnt") > 1)
    .orderBy(F.col("cnt").desc())
)

print("--- Duplicate Parent NHA Report ---")
if duplicate_check.count() > 0:
    print("⚠️ ALERT: Duplicates found! The current Spark logic is DIFFERENT from SAP.")
    print("SAP sums these quantities; Spark creates multiple rows.")
    duplicate_check.show(10, truncate=False)
else:
    print("✅ SAFE: No duplicates found. The current Spark logic matches SAP results.")
