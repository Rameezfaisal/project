# Cell 7: Final Validation (Sanity Check)

# 1. Check for duplicates on the Primary Key
# The natural key should likely be Order + Line + Schedule Line
duplicates_df = spark.read.table(paths["target"]) \
    .groupBy("order", "line", "scheduleline") \
    .count() \
    .filter("count > 1")

dup_count = duplicates_df.count()

if dup_count == 0:
    print(f"‚úÖ DATA INTEGRITY PASS: No duplicates found for Order/Line/ScheduleLine.")
else:
    print(f"‚ö†Ô∏è WARNING: Found {dup_count} duplicate keys. Investigate immediately.")
    duplicates_df.show(5)

# 2. Financial Total Check
# Compare total value to ensure no massive explosion
total_value = spark.read.table(paths["target"]).agg(F.sum("grosssopriceusd")).collect()[0][0]
print(f"üí∞ Total Gross Value (USD) in Target: ${total_value:,.2f}")
