from pyspark.sql import functions as F
from pyspark.sql import Window


# Source
tbl_ipln_pr_part = "lakehouse_ipln.cv_iplm_problem_report_part"

# Target
tbl_omat_obprtno_dtls = "lakehouse_omat.omat_obprtno_dtls"
tbl_omat_log_dtls     = "lakehouse_omat.omat_log_dtls"

# Runtime
run_ts = F.current_timestamp()




df_obpr = spark.table(tbl_omat_obprtno_dtls)

df_iplm = (
    spark.table(tbl_ipln_pr_part)
    .select(
        F.col("name").alias("src_obprno"),
        F.col("part_name").alias("src_obprtno"),
        F.col("state").alias("src_state"),
        F.col("reason").alias("src_reason"),
        F.col("disposition").alias("src_disposition"),
        F.col("mstae").alias("src_part_status"),
        F.col("is_the_last_time_buy_available").alias("src_is_ltb_avail"),
        F.col("ob_last_buy_date").alias("src_ltb_date"),
        F.col("lrc_suppliers_date_to_zero_inventory").alias("src_supplier_zero_dt"),
        F.col("submitted_date").alias("src_submitted_dt")
    )
)






spark.sql(f"""
INSERT INTO {tbl_omat_log_dtls} (message, val1, val2, val3, log_ts)
VALUES ('SP_OMAT_UPDATEOBPR_WklyRefresh - Started', 0, 0, 0, current_timestamp())
""")