AnalysisException                         Traceback (most recent call last)
Cell In[40], line 15
      6 zpo_hist_df = read_union_fast("zpo_hstry").selectExpr(
      7     "matnr as matnr_hist","ebeln","ebelp","menge","wemng",
      8     "lgort","lifnr as ltbposupplier","closed","status",
      9     "lnkd_doc","lnkd_itm"
     10 )
     12 ltb_union_df = zpo_hist_df.filter(F.col("closed")=="CLSCOMP")
     14 part_supp_df = eban_df.alias("e") \
---> 15     .join(ltb_union_df.alias("h"),
     16           (F.col("e.ebeln")==F.col("h.ebeln")) &
     17           (F.col("e.ebelp")==F.col("h.ebelp")),
     18           "inner") \
     19     .filter((F.col("e.ekgrp")=="LTB") & (F.col("e.loekz")!="X")) \
     20     .groupBy("matnr_hist","ltbpono","ltbposupplier") \
     21     .agg(
     22         F.sum("menge").alias("qtyrequested"),
     23         F.sum("wemng").alias("qtyreceived")
     24     ) \
     25     .withColumn(
     26         "ltb_status",
     27         F.when(F.col("qtyrequested")==F.col("qtyreceived"),"LTB COMPLETED")
     28          .when(F.col("qtyreceived").isNull(),"LTB CANCELLED")
     29          .otherwise("LTB PO OPENED")
     30     ) \
     31     .filter(F.col("ltb_status")=="LTB PO OPENED")

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:2493, in DataFrame.join(self, other, on, how)
   2491         on = self._jseq([])
   2492     assert isinstance(how, str), "how should be a string"
-> 2493     jdf = self._jdf.join(other._jdf, on, how)
   2494 return DataFrame(jdf, self.sparkSession)

File ~/cluster-env/trident_env/lib/python3.11/site-packages/py4j/java_gateway.py:1322, in JavaMember.__call__(self, *args)
   1316 command = proto.CALL_COMMAND_NAME +\
   1317     self.command_header +\
   1318     args_command +\
   1319     proto.END_COMMAND_PART
   1321 answer = self.gateway_client.send_command(command)
-> 1322 return_value = get_return_value(
   1323     answer, self.gateway_client, self.target_id, self.name)
   1325 for temp_arg in temp_args:
   1326     if hasattr(temp_arg, "_detach"):

File /opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:185, in capture_sql_exception.<locals>.deco(*a, **kw)
    181 converted = convert_exception(e.java_exception)
    182 if not isinstance(converted, UnknownException):
    183     # Hide where the exception came from that shows a non-Pythonic
    184     # JVM exception message.
--> 185     raise converted from None
    186 else:
    187     raise

AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `e`.`ebeln` cannot be resolved. Did you mean one of the following? [`h`.`ebeln`, `h`.`ebelp`, `e`.`banfn`, `e`.`bnfpo`, `e`.`ekgrp`].;
'Join Inner, (('e.ebeln = ebeln#4282) AND ('e.ebelp = ebelp#4283))
:- SubqueryAlias e
:  +- Project [banfn#2456, bnfpo#2457, erdat#2469, frgdt#2485, lifnr#2498 AS prereq_supplier#4216, ebeln#2513 AS ltbpo
