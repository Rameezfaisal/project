from pyspark.sql import functions as F

# ------------------------------------------------------------------
# Step 0: Re-materialize a CLEAN obprdtls (this is the key fix)
# ------------------------------------------------------------------
clean_obprdtls = (
    obprdtls_df
    .select(
        F.col("ob_prno").alias("ob_prno"),
        F.col("ob_prtno").alias("ob_prtno")
    )
    .distinct()
)

# ------------------------------------------------------------------
# Step 1: Join + project only required columns
# ------------------------------------------------------------------
joined_df = (
    clean_obprdtls
    .join(
        df_omat_src,
        (clean_obprdtls.ob_prtno == df_omat_src.obprtno) &
        (~F.upper(df_omat_src.obpr_state).isin("CLOSED", "CANCELLED")),
        "left"
    )
    .join(
        df_iplm,
        (df_iplm.part_name == clean_obprdtls.ob_prtno) &
        (df_iplm.name != clean_obprdtls.ob_prno) &
        (F.upper(df_iplm.state) != "CLOSED") &
        (
            (F.upper(df_iplm.state).isin("CONFIRMED","IN REVIEW","IN WORK")) |
            (F.upper(df_iplm.disposition).isin("CONFIRMED","DEFER"))
        ) &
        (F.upper(df_iplm.reason) == "OBSOLETE COMPONENT"),
        "left"
    )
    .select(
        clean_obprdtls.ob_prno.alias("ob_prno"),
        clean_obprdtls.ob_prtno.alias("ob_prtno"),
        df_omat_src.obprtno.alias("omat_obprtno"),
        df_omat_src.reltd_ob_pr.alias("omat_reltd_ob_pr"),
        df_iplm.name.alias("iplm_prno")
    )
)

# ------------------------------------------------------------------
# Step 2: Aggregate (no ambiguity possible now)
# ------------------------------------------------------------------
related_prs_df = (
    joined_df
    .groupBy("ob_prno", "ob_prtno")
    .agg(
        F.when(
            F.count("omat_obprtno") == 0,
            F.concat_ws(",", F.collect_set("iplm_prno"))
        )
        .otherwise(F.max("omat_reltd_ob_pr"))
        .alias("reltd_ob_prs")
    )
)

related_prs_df.createOrReplaceTempView("related_prs")