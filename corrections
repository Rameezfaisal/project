%%sql
CREATE TABLE IF NOT EXISTS lakehouse.target_materialized_table (
    booking                 STRING,
    carrier                 STRING,
    carrier_name            STRING,
    dlvstatus               STRING,
    etenr                   STRING NOT NULL, -- PK/Key
    expectedqtycumulative   DECIMAL(13,3),
    f1_vbeln                STRING,
    frontload               STRING,
    last_changed            TIMESTAMP,
    lastpgidoc              STRING,
    mard_kinsm              DECIMAL(13,3),
    mard_klabs              DECIMAL(13,3),
    mard_labst              DECIMAL(13,3),
    mard_lgort              STRING,
    mard_matnr              STRING,
    mard_werks              STRING,
    order_status            STRING,
    opendlvdoc              STRING,
    opendlvqty              DECIMAL(13,3),
    pgidate                 DATE,
    pgiqty                  DECIMAL(15,3),
    poreceived              STRING,
    posnr                   STRING NOT NULL, -- PK/Key
    qtyshippedttline        DECIMAL(13,3),
    shipto                  STRING,
    shiptoname              STRING,
    vbak_auart              STRING,
    vbak_aufnr              STRING,
    vbak_autlf              STRING,
    vbak_bstnk              STRING,
    vbak_erdat              DATE,
    vbak_ernam              STRING,
    vbak_faksk              STRING,
    vbak_ihrez              STRING,
    vbak_kunnr              STRING,
    vbak_lifsk              STRING,
    vbak_netwr              DECIMAL(15,2),
    vbak_objnr              STRING,
    vbak_vkorg              STRING,
    vbak_vsnmr_v            STRING,
    vbak_waerk              STRING,
    vbap_abgru              STRING,
    vbap_aedat              DATE,
    vbap_arktx              STRING,
    vbap_charg              STRING,
    vbap_erdat              DATE,
    vbap_ernam              STRING,
    vbap_erzet              STRING, -- Mapped TIME to STRING for compatibility
    vbap_faksp              STRING,
    vbap_grkor              STRING,
    vbap_kdmat              STRING,
    vbap_kwmeng             DECIMAL(15,3),
    vbap_lgort              STRING,
    vbap_lprio              STRING,
    vbap_matnr              STRING,
    vbap_netpr              DECIMAL(11,2),
    vbap_posex              STRING,
    vbap_prodh              STRING,
    vbap_vstel              STRING,
    vbap_werks              STRING,
    vbeln                   STRING NOT NULL, -- PK/Key
    vbep_bmeng              DECIMAL(13,3),
    vbep_edatu              DATE,
    vbep_h_edatu            DATE,
    vbep_lifsp              STRING,
    vbep_mbdat              DATE,
    vbuk_lfgsk              STRING,
    vbuk_wbstk              STRING,
    vbup_lfsta              STRING,
    delvd_qty               DOUBLE
) USING DELTA;










# CELL 1: Imports
from pyspark.sql import functions as F
from pyspark.sql.window import Window
from pyspark.sql.types import DecimalType, DoubleType, DateType, TimestampType

# Set Spark to legacy time parser if incoming dates have mixed formats, 
# otherwise ANSI defaults are preferred in Fabric.
spark.conf.set("spark.sql.legacy.timeParserPolicy", "CORRECTED")










# CELL 2: Parameters & Configuration
# -------------------------------------------------------------------------
# DEFINE ALL SOURCE PATHS HERE. DO NOT HARDCODE IN LOGIC.
# -------------------------------------------------------------------------

params = {
    # Transactional Tables
    "vbak": "lakehouse.cvns_vbak",
    "vbap": "lakehouse.cvns_vbap",
    "vbep": "lakehouse.cvns_vbep",
    "vbuk": "lakehouse.cv_vbuk",
    "vbup": "lakehouse.cv_vbup",
    "vbfa": "lakehouse.cv_vbfa",
    "lips": "lakehouse.cvns_lips",
    "likp": "lakehouse.cvns_likp",
    "vbkd": "lakehouse.cvns_vbkd",
    "vbpa": "lakehouse.cv_vbpa",
    
    # Master Data / Lookups
    "kna1": "lakehouse.cv_kna1",
    "mara": "lakehouse.cv_mara",
    "marc": "lakehouse.cv_marc",
    "mard": "lakehouse.cv_mard",
    "mbew": "lakehouse.cv_mbew",
    "part": "lakehouse.cv_part", # Custom View
    "t024x": "lakehouse.cv_t024x",
    "jest": "lakehouse.cv_jest",
    "tj30t": "lakehouse.cv_tj30t",
    "vekp": "lakehouse.cv_vekp",
    "qmel": "lakehouse.cvns_qmel",
    "spares": "lakehouse.cvns_csbg_spares_deliveries_new",
    "afko": "lakehouse.cv_afko",
    "afvc": "lakehouse.cv_afvc",
    
    # Target
    "target_table": "lakehouse.target_materialized_table"
}









# CELL 3: Read Source DataFrames
# Reading strictly necessary tables and applying standard lowercase aliases

# Header & Item
df_vbak = spark.read.table(params["vbak"]).alias("a")
df_vbap = spark.read.table(params["vbap"]).alias("p")
df_vbep = spark.read.table(params["vbep"]).alias("e") # Schedule lines
df_vbuk = spark.read.table(params["vbuk"]).alias("u")
df_vbup = spark.read.table(params["vbup"]).alias("b")

# Master Data
df_kna1 = spark.read.table(params["kna1"]).alias("k")
df_mara = spark.read.table(params["mara"]).alias("m")
df_marc = spark.read.table(params["marc"]).alias("z")
df_mard = spark.read.table(params["mard"]).alias("r")
df_mbew = spark.read.table(params["mbew"]).alias("w")
df_part = spark.read.table(params["part"]).alias("pp")

# Helper Tables
df_vbfa = spark.read.table(params["vbfa"])
df_lips = spark.read.table(params["lips"])
df_likp = spark.read.table(params["likp"])
df_vbkd = spark.read.table(params["vbkd"])
df_vbpa = spark.read.table(params["vbpa"])
df_jest = spark.read.table(params["jest"])
df_tj30t = spark.read.table(params["tj30t"])
df_vekp = spark.read.table(params["vekp"])
df_qmel = spark.read.table(params["qmel"]).alias("q")
df_spares = spark.read.table(params["spares"])
df_afko = spark.read.table(params["afko"]).alias("afko")
df_afvc = spark.read.table(params["afvc"])
df_t024x = spark.read.table(params["t024x"]).alias("i")

# Helper for Lab Office
df_lab = df_t024x.filter(F.col("spras") == 'E')
