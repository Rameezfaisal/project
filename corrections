# 1. Get stats safely (Count always returns a row, even if 0)
stats = spark.sql("""
    SELECT 
        COUNT(DISTINCT ob_prtno) as part_cnt, 
        COUNT(DISTINCT ob_prno) as pr_cnt,
        first(ob_prno) as example_pr
    FROM obprdtls
""").first()

# 2. Create single log row
log_data = [Row(
    executed_on = F.current_timestamp(),
    obprtno_cnt = stats['part_cnt'],
    obprtno_nha_cnt = 0,
    obpr_cnt = stats['pr_cnt'],
    program_name = f"nb_omat_insert_newobpr_wklyrefresh - {stats['example_pr'] or 'No_New_Data'}"
)]

# 3. Write to table
spark.createDataFrame(log_data).select(
    "executed_on", "obprtno_cnt", "obprtno_nha_cnt", "obpr_cnt", "program_name"
).write.format("delta").mode("append").save(tbl_omat_log_tgt)
