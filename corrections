---------------------------------------------------------------------------
Py4JJavaError                             Traceback (most recent call last)
Cell In[85], line 10
      4 final_df.createOrReplaceTempView("source_updates")
      6 # 2. Execute the MERGE Statement
      7 # Note: We assume the target table 'T_SO_STATUS' already exists with the correct schema.
      8 # If this is the very first run, you might use: final_df.write.format("delta").saveAsTable(T_SO_STATUS)
---> 10 spark.sql(f"""
     11 MERGE INTO {T_SO_STATUS} AS target
     12 USING source_updates AS source
     13 ON target.VBELN = source.VBELN 
     14    AND target.POSNR = source.POSNR 
     15    AND target.ETENR = source.ETENR
     16 
     17 WHEN MATCHED THEN
     18   UPDATE SET *
     19 
     20 WHEN NOT MATCHED THEN
     21   INSERT *
     22 """)

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/session.py:1631, in SparkSession.sql(self, sqlQuery, args, **kwargs)
   1627         assert self._jvm is not None
   1628         litArgs = self._jvm.PythonUtils.toArray(
   1629             [_to_java_column(lit(v)) for v in (args or [])]
   1630         )
-> 1631     return DataFrame(self._jsparkSession.sql(sqlQuery, litArgs), self)
   1632 finally:
   1633     if len(kwargs) > 0:

File ~/cluster-env/trident_env/lib/python3.11/site-packages/py4j/java_gateway.py:1322, in JavaMember.__call__(self, *args)
   1316 command = proto.CALL_COMMAND_NAME +\
   1317     self.command_header +\
   1318     args_command +\
   1319     proto.END_COMMAND_PART
   1321 answer = self.gateway_client.send_command(command)
-> 1322 return_value = get_return_value(
   1323     answer, self.gateway_client, self.target_id, self.name)
   1325 for temp_arg in temp_args:
   1326     if hasattr(temp_arg, "_detach"):

File /opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:179, in capture_sql_exception.<locals>.deco(*a, **kw)
    177 def deco(*a: Any, **kw: Any) -> Any:
    178     try:
--> 179         return f(*a, **kw)
    180     except Py4JJavaError as e:
    181         converted = convert_exception(e.java_exception)

File ~/cluster-env/trident_env/lib/python3.11/site-packages/py4j/protocol.py:326, in get_return_value(answer, gateway_client, target_id, name)
    324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
    325 if answer[1] == REFERENCE_TYPE:
--> 326     raise Py4JJavaError(
    327         "An error occurred while calling {0}{1}{2}.\n".
    328         format(target_id, ".", name), value)
    329 else:
    330     raise Py4JError(
    331         "An error occurred while calling {0}{1}{2}. Trace:\n{3}\n".
    332         format(target_id, ".", name, value))

Py4JJavaError: An error occurred while calling o407.sql.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 306.0 failed 4 times, most recent failure: Lost task 0.3 in stage 306.0 (TID 2830) (vm-0e184064 executor 3): org.apache.spark.SparkException: [TASK_WRITE_FAILED] Task failed while writing rows to abfss://1d087dee-28bf-4ed5-9d53-1138f15f786f@onelake.dfs.fabric.microsoft.com/d562810f-a154-4f8d-9788-f57b96d02df4/Tables/eng_test/sales_order.
	at org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:777)
	at org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.executeTask(DeltaFileFormatWriter.scala:621)
	at org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.$anonfun$executeWrite$2(DeltaFileFormatWriter.scala:362
