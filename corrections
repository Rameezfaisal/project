# --- 1. SIMPLE DIMENSIONS ---
df_kna1 = spark.read.table(S_KNA1).select("kunnr", "name1")
df_mara = spark.read.table(S_MARA).select("matnr", "matkl", "labor", "mstae")
df_marc = spark.read.table(S_MARC).select("matnr", "werks", "dispo", "ekgrp")
df_part = spark.read.table(S_PART).select(F.col("Part").alias("part_matnr"), "Consumable")
df_t024x = spark.read.table(S_T024X).filter(F.col("spras") == CONST_LANG_KEY).select("labor", "lbtxt")
df_qmel = spark.read.table(S_QMEL).select(F.col("aufnr").alias("qmel_aufnr"), F.col("qmnum"))

# --- 2. COST LOGIC (MBEW) ---
# We need Standard Price (STPRS) for two specific Valuation Areas (Plants)
df_mbew_raw = spark.read.table(S_MBEW).select("matnr", "bwkey", "stprs")

ds_mbew_2000 = df_mbew_raw.filter(F.col("bwkey") == "2000").select(
    F.col("matnr").alias("mbew2_matnr"), 
    F.col("stprs").alias("stprs_2000")
)

ds_mbew_3120 = df_mbew_raw.filter(F.col("bwkey") == "3120").select(
    F.col("matnr").alias("mbew3_matnr"), 
    F.col("stprs").alias("stprs_3120")
)

# --- 3. TRACKING LOGIC (VEKP) ---
# SAP: MAX(EXIDV2) GROUP BY VPOBJKEY
ds_vekp = spark.read.table(S_VEKP).groupBy("vpobjkey").agg(
    F.max("exidv2").alias("exidv2")
)

# --- 4. INCOTERMS LOGIC (VBKD) ---
df_vbkd = spark.read.table(S_VBKD).select("vbeln", "posnr", "inco1", "kursk", "prsdt", "ihrez", "zterm")

# Header Level (POSNR = 000000)
ds_vbkd_h = df_vbkd.filter(F.col("posnr") == "000000").select(
    F.col("vbeln").alias("h_vbeln"),
    F.col("inco1").alias("h_inco1"),
    F.col("kursk").alias("h_kursk"),
    F.col("prsdt").alias("h_prsdt")
)

# Item Level (All POSNR)
ds_vbkd_i = df_vbkd.select(
    F.col("vbeln").alias("i_vbeln"),
    F.col("posnr").alias("i_posnr"),
    F.col("inco1").alias("i_inco1"),
    F.col("ihrez").alias("i_ihrez"),
    F.col("zterm").alias("i_zterm")
)

# --- 5. ACTIVITY TYPE LOGIC (AFKO/AFVC) ---
# Complex Logic: Get Activity Type (LARNT) from the "First Operation" (MIN VORNR) of a Service Order
df_afko = spark.read.table(S_AFKO).select("aufnr", "aufpl")
df_afvc = spark.read.table(S_AFVC).select("aufpl", "vornr", "larnt")

# Step A: Find the first operation (VORNR) for each Plan (AUFPL)
ds_first_op = df_afvc.groupBy("aufpl").agg(F.min("vornr").alias("min_vornr"))

# Step B: Join back to get LARNT, then Join to AFKO to get AUFNR
ds_act = ds_first_op.join(
    df_afvc,
    (ds_first_op.aufpl == df_afvc.aufpl) & (ds_first_op.min_vornr == df_afvc.vornr)
).join(
    df_afko, "aufpl"
).select(
    F.col("aufnr").alias("act_aufnr"),
    F.col("larnt").alias("act_larnt")
)









AnalysisException                         Traceback (most recent call last)
Cell In[85], line 12
      1 # --- CELL 4: LOGIC & FINAL SELECT ---
      2 
      3 # 1. Join Dimensions to Fact (Left Joins)
      4 # We use hints to speed up the smaller table joins
      5 df_logic = df_base.alias("f") \
      6     .join(df_kna1.hint("broadcast"), F.col("f.VBAK_KUNNR") == F.col("k_kunnr"), "left") \
      7     .join(df_mara.hint("broadcast"), F.col("f.VBAP_MATNR") == F.col("m_matnr"), "left") \
      8     .join(df_part.hint("broadcast"), F.col("f.VBAP_MATNR") == F.col("p_matnr"), "left") \
      9     .join(df_marc, (F.col("f.VBAP_WERKS") == F.col("werks")) & (F.col("f.VBAP_MATNR") == F.col("matnr")), "left") \
     10     .join(ds_mbew_2000.hint("broadcast"), F.col("f.VBAP_MATNR") == F.col("m2_matnr"), "left") \
     11     .join(ds_mbew_3120.hint("broadcast"), F.col("f.VBAP_MATNR") == F.col("m3_matnr"), "left") \
---> 12     .join(df_t024x.hint("broadcast"), F.col("labor") == F.col("labor"), "left") \
     13     .join(df_qmel, F.col("f.VBELN") == F.col("qmel_aufnr"), "left") \
     14     .join(ds_act, F.col("f.VBAK_AUFNR") == F.col("act_aufnr"), "left") \
     15     .join(ds_vekp, F.col("f.F1_VBELN") == F.col("vpobjkey"), "left") \
     16     .join(ds_vbkd_h, F.col("f.VBELN") == F.col("h_vbeln"), "left") \
     17     .join(ds_vbkd_i, (F.col("f.VBELN") == F.col("i_vbeln")) & (F.col("f.POSNR") == F.col("i_posnr")), "left")
     19 # 2. Pre-Calculation Expressions (To keep Select clean)
     20 # Currency Rate Logic (Handle JPY/TWD scaling and 0/USD rates)
     21 exp_kursk_valid = F.when((F.coalesce(F.col("h_kursk"), F.lit(0)) == 0) | (F.col("f.VBAK_WAERK") == "USD"), 1.0).otherwise(F.col("h_kursk"))

File /opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:2493, in DataFrame.join(self, other, on, how)
   2491         on = self._jseq([])
   2492     assert isinstance(how, str), "how should be a string"
-> 2493     jdf = self._jdf.join(other._jdf, on, how)
   2494 return DataFrame(jdf, self.sparkSession)

File ~/cluster-env/trident_env/lib/python3.11/site-packages/py4j/java_gateway.py:1322, in JavaMember.__call__(self, *args)
   1316 command = proto.CALL_COMMAND_NAME +\
   1317     self.command_header +\
   1318     args_command +\
   1319     proto.END_COMMAND_PART
   1321 answer = self.gateway_client.send_command(command)
-> 1322 return_value = get_return_value(
   1323     answer, self.gateway_client, self.target_id, self.name)
   1325 for temp_arg in temp_args:
   1326     if hasattr(temp_arg, "_detach"):

File /opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:185, in capture_sql_exception.<locals>.deco(*a, **kw)
    181 converted = convert_exception(e.java_exception)
    182 if not isinstance(converted, UnknownException):
    183     # Hide where the exception came from that shows a non-Pythonic
    184     # JVM exception message.
--> 185     raise converted from None
    186 else:
    187     raise

AnalysisException: [AMBIGUOUS_REFERENCE] Reference `labor` is ambiguous, could be: [`spark_catalog`.`chimcobldhq2atrjcpfn6qbcddfmer32bti62nr4clr2ar38edfmer324lim6oo`.`mara`.`labor`, `spark_catalog`.`chimcobldhq2atrjcpfn6qbcddfmer32bti62nr4clr2ar38edfmer324lim6oo`.`t024x`.`labor`].
